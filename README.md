# Multilayer Perceptron

A multilayer perceptron (MLP) is a class of feedforward artificial neural network. A MLP consists of, at least, three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Its multiple layers and non-linear activation distinguish MLP from a linear perceptron. It can distinguish data that is not linearly separable.

## Purpose
A program which can classify sets of data.</br>
User choose a file from the dataset, and then enter a learning rate, number of iterations, number of hidden layers, l2 parameter and the batch size.</br>
At last, user click on train or test button to see the result of classification and accuracy.</br>

## Results
<img src="https://github.com/jeannineshiu/Multilayer-Perceptron/blob/master/interface.png" width = "600" height = "500" alt="interface.png" align=center />
<img src="https://github.com/jeannineshiu/Multilayer-Perceptron/blob/master/result01.png" width = "600" height = "500" alt="result01.png" align=center />
<img src="https://github.com/jeannineshiu/Multilayer-Perceptron/blob/master/result02.png" width = "600" height = "500" alt="result02.png" align=center />
